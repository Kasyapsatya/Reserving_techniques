{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kasyapsatya/Reserving_techniques/blob/neural-networks/Stochio_Deterministic_Package.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aq6IA3pNqy2"
      },
      "source": [
        "Estimating Ultimate Costs Using Deterministic and Stochastic Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2lJ7Q9tYntH4",
        "outputId": "46abd669-ce26-453d-9fb0-73f55347407b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nLet's create a package in python\\nA package for Actuaries\\nA package for Actuarial Reserving devoloped from scratch\\nThis already has the entire NAIC schedule P data analysed and also will be able to take data(with few-constraints) and generate the results into an excel sheet\\n\""
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Let's create a package in python\n",
        "A package for Actuaries\n",
        "A package for Actuarial Reserving devoloped from scratch\n",
        "This already has the entire NAIC schedule P data analysed and also will be able to take data(with few-constraints) and generate the results into an excel sheet\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMrSW5L1N70H"
      },
      "source": [
        "[Date Pre-processing Colab:](https://colab.research.google.com/drive/1KKn8LZeFQJ95bVUnXMLb2rIK-pa2io9I?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDKKa4sioz63",
        "outputId": "740bed54-72b8-44fe-92e1-98b90da1a759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.14.1)\n",
            "Requirement already satisfied: numpy<2,>=1.18 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels) (1.26.4)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels) (1.13.0)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.0 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels) (2.2.1)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from statsmodels) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2024.1)\n",
            "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement copy (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for copy\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tabulate in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.9.0)\n",
            "Requirement already satisfied: XlsxWriter in /usr/local/python/3.10.13/lib/python3.10/site-packages (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import warnings\n",
        "!pip install statsmodels\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import r2_score\n",
        "!pip install copy\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "!pip install tabulate\n",
        "from tabulate import tabulate\n",
        "import seaborn as sns\n",
        "from classes import triangle_tri, method_triangle, triangle, report, GLM, method\n",
        "!pip install XlsxWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUUSstgiOLBp"
      },
      "source": [
        "For a single company"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "efBYUTn4CFv7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'copy' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m gr\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m669\u001b[39m \u001b[38;5;66;03m#44504\u001b[39;00m\n\u001b[1;32m      6\u001b[0m Actuary\u001b[38;5;241m=\u001b[39mmethod()\n\u001b[0;32m----> 7\u001b[0m results\u001b[38;5;241m=\u001b[39m[\u001b[43mActuary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgr\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(tabulate(results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][gr], showindex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m , headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m'\u001b[39m, tablefmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsql\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "File \u001b[0;32m/workspaces/Reserving_techniques/classes.py:677\u001b[0m, in \u001b[0;36mmethod.methods\u001b[0;34m(self, df, gr, flag)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmethods\u001b[39m(\u001b[38;5;28mself\u001b[39m,df,gr,flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    676\u001b[0m   Actuary_validate\u001b[38;5;241m=\u001b[39mtriangle()\n\u001b[0;32m--> 677\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpivottables_verify\u001b[38;5;241m=\u001b[39m\u001b[43mActuary_validate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_triangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpaid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#for verification\u001b[39;00m\n\u001b[1;32m    679\u001b[0m   df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccidentYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevelopmentLag\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1998\u001b[39m]  \u001b[38;5;66;03m#upper triangle\u001b[39;00m\n\u001b[1;32m    680\u001b[0m   \u001b[38;5;66;03m#df.info()\u001b[39;00m\n",
            "File \u001b[0;32m/workspaces/Reserving_techniques/classes.py:171\u001b[0m, in \u001b[0;36mtriangle.get_triangle\u001b[0;34m(self, df, gr, paid, reported)\u001b[0m\n\u001b[1;32m    169\u001b[0m pivot_table \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39mpivot_table(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccidentYear\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevelopmentLag\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumPaidLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpivottables[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgr] \u001b[38;5;241m=\u001b[39m pivot_table\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_pivottables \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpivottables)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglm_pivottables\u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpivottables)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m#print(\"Upper Triangle:\", self.pivottables[self.gr] )\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'copy' is not defined"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('merged_data.csv')\n",
        "df = df[df['Line_of_Business_LOB2'] == 1]\n",
        "df_filtered= df[(df['AccidentYear'] + df['DevelopmentLag']) <= 1998] #upper trianlge\n",
        "#take a company code\n",
        "gr= 669 #44504\n",
        "Actuary=method()\n",
        "results=[Actuary.methods(df,gr)]\n",
        "print(results)\n",
        "print(tabulate(results[0][0][gr], showindex=True , headers='keys', tablefmt = 'psql'))\n",
        "#results[0][2]['Chain Ladder'] is our chianladder UC reserve estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSHOV4PnOO3r"
      },
      "source": [
        "Analysis of multiple companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaWMHriM8cyE"
      },
      "outputs": [],
      "source": [
        "#LOB1->commercial auto\n",
        "#LOB2->medical malpractices\n",
        "#LOB3->other liabilities\n",
        "#LOB4->private passengers\n",
        "#LOB5->product liabilities\n",
        "#LOB6->worker's compensation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ0sdh33mvzg"
      },
      "outputs": [],
      "source": [
        "random_elements=[\n",
        "    [337,353,388,620, 715],\n",
        "    [669,7854,32514,33049,33111],\n",
        "    [460,620,671,683,715],\n",
        "    [43,266,353,388,460],\n",
        "    [78,86,353,388,620],\n",
        "    [86,337,353,388,671]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqw6LHrfWb4y"
      },
      "outputs": [],
      "source": [
        "column_names = ['LOB','gr', 'Chain Ladder', 'ARIMA Chain Ladder', 'Expected Ult Loss', 'BF','Cape-cod Ult paid claims', 'GLM','GLM2','GLM2(2)', 'Original UC', 'GLM Bootstrap', 'GLM Bootstrap CL',\n",
        "                  'Error in Chian Ladder', 'Error in ARIMA Chain Ladder', 'Error in Expected Ult Loss','Error in BF', 'Error in Cape-cod Ult paid claims', 'Error in GLM','Error in GLM2','Error in GLM2(2)','Error in GLM Bootstrap','Error in GLM Bootstrap CL','Best R2', 'Best in terms of error in UC']\n",
        "print(len(column_names))\n",
        "info = pd.DataFrame(columns=column_names)\n",
        "for i in range(1,7):\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Shashi/merged_data.csv')\n",
        "  string='Line_of_Business_LOB{}'.format(i)\n",
        "  #print(string)\n",
        "  df=df[df[string]==1]\n",
        "  for gr in random_elements[i-1]:\n",
        "    Actuary=method()\n",
        "    results=[Actuary.methods(df,gr)]\n",
        "    #print(results)\n",
        "    #print(results[0][2])\n",
        "    #print(results[0][1])\n",
        "    errors={}\n",
        "    for key, valaue in results[0][2].items():\n",
        "        if key!='Original UC':\n",
        "          errors[key]=results[0][2][key]-results[0][2]['Original UC']\n",
        "\n",
        "\n",
        "    max_key = max(results[0][1], key=results[0][1].get)      #max R2\n",
        "    min_key=min(errors, key=lambda k: abs(errors[k]))        #min UC error\n",
        "    input=[list(results[0][2].values()),list(errors.values()),max_key, min_key]\n",
        "    input_row = [element for sublist in input for element in sublist if type(element) != str]\n",
        "    input_row.append(input[-2])\n",
        "    input_row.append(input[-1])\n",
        "    input_row.insert(0,gr)\n",
        "    input_row.insert(0,i)\n",
        "    print(input_row)\n",
        "    print(len(input_row))\n",
        "    #append input_row to info\n",
        "    info.loc[len(info)]=input_row\n",
        "    #info = info.append(input_row, ignore_index=True)\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUv5NR_HgOaf"
      },
      "outputs": [],
      "source": [
        "dup = copy.deepcopy(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRBkKlfIqgin",
        "outputId": "21089d02-bd72-4e12-8bb4-9703b9bad688"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-70ae07816973>:12: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  writer.save()\n"
          ]
        }
      ],
      "source": [
        "writer= pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
        "info.to_excel(writer, index=False, sheet_name='results', startrow=1)\n",
        "\n",
        "# Access the xlsxwriter workbook and worksheet objects\n",
        "workbook  = writer.book\n",
        "worksheet = writer.sheets['results']\n",
        "\n",
        "# Set the width of all columns to 15\n",
        "for col_num, value in enumerate(info.columns.values):\n",
        "    worksheet.set_column(col_num, col_num, width=28)\n",
        "# Save the Excel file\n",
        "writer.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGaHpRa-OUSc"
      },
      "source": [
        "Download the output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCi51CRIq4OF"
      },
      "outputs": [],
      "source": [
        "#AWESOME- DONE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
