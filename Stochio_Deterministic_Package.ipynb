{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kasyapsatya/Reserving_techniques/blob/neural-networks/Stochio_Deterministic_Package.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aq6IA3pNqy2"
      },
      "source": [
        "Estimating Ultimate Costs Using Deterministic and Stochastic Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lJ7Q9tYntH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "46abd669-ce26-453d-9fb0-73f55347407b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nLet's create a package in python\\nA package for Actuaries\\nA package for Actuarial Reserving devoloped from scratch\\nThis already has the entire NAIC schedule P data analysed and also will be able to take data(with few-constraints) and generate the results into an excel sheet\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "Let's create a package in python\n",
        "A package for Actuaries\n",
        "A package for Actuarial Reserving devoloped from scratch\n",
        "This already has the entire NAIC schedule P data analysed and also will be able to take data(with few-constraints) and generate the results into an excel sheet\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMrSW5L1N70H"
      },
      "source": [
        "[Date Pre-processing Colab:](https://colab.research.google.com/drive/1KKn8LZeFQJ95bVUnXMLb2rIK-pa2io9I?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDKKa4sioz63",
        "outputId": "740bed54-72b8-44fe-92e1-98b90da1a759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting XlsxWriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter\n",
            "Successfully installed XlsxWriter-3.2.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import warnings\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import r2_score\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "!pip install XlsxWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6F1Ou7lBYz3"
      },
      "outputs": [],
      "source": [
        "#for triangular data      DONE\n",
        "class triangle_tri() :\n",
        "  def get_triangle(self,Triangle,num_bootstrap_samples=1000,paid=0,reported=0):\n",
        "    self.gr=1\n",
        "    self.pivottables = {}\n",
        "    if paid==1:\n",
        "      pivot_table = Triangle\n",
        "      self.pivottables[self.gr] = pivot_table\n",
        "      self.arima_pivottables = copy.deepcopy(self.pivottables)\n",
        "      #print(\"Upper Triangle:\", self.pivottables[self.gr] )\n",
        "      return self.pivottables\n",
        "    if reported==1:\n",
        "      pivot_table = Triangle\n",
        "      self.pivottables[self.gr] = pivot_table\n",
        "      self.arima_pivottables = copy.deepcopy(self.pivottables)\n",
        "      #print(\"Upper Triangle:\", self.pivottables[self.gr] )\n",
        "      return self.pivottables\n",
        "\n",
        "\n",
        "  def init(self):\n",
        "    for gr_code, pivot_table in self.pivottables.items():\n",
        "      self.agefactors={}\n",
        "      factors=[]\n",
        "      for i in range(9):\n",
        "        P = []\n",
        "        for j in range(9):\n",
        "          if (pivot_table.iloc[i,j] != 0):\n",
        "            f = round(pivot_table.iloc[i,j+1]/pivot_table.iloc[i,j],4)\n",
        "          elif (pivot_table.iloc[i,j] == 0 and pivot_table.iloc[i,j+1] == 0 ):\n",
        "            f = 1\n",
        "          else:\n",
        "            f = None\n",
        "          P.append(f)\n",
        "        factors.append(P)\n",
        "      Accident_Year = [1988+i for i in range(9)]\n",
        "      col = [(12*(i+1),12*(i+2)) for i in range(9)]\n",
        "      DF = pd.DataFrame.from_records(factors,columns = col, index = Accident_Year)\n",
        "      self.agefactors[self.gr]=DF\n",
        "      #print(\"Age-age factors:\", self.agefactors[self.gr] )\n",
        "    #def cap_ages(self):\n",
        "    for gr_code, factors in self.agefactors.items():\n",
        "      for i in range(9):\n",
        "        his=[]\n",
        "        for j in range(9):\n",
        "          value=factors.iloc[j,i]\n",
        "          try:\n",
        "              del sum\n",
        "          except :\n",
        "              pass  #somewhere sum is defined as an integer\n",
        "          if his:\n",
        "            count=0\n",
        "            for i in range(len(his)):\n",
        "              count+=his[i]\n",
        "            his_sum = count\n",
        "            mean=his_sum/len(his)\n",
        "            limit=mean+5\n",
        "            if value>limit:\n",
        "              factors.iloc[j,i]=mean\n",
        "          his.append(factors.iloc[j,i])\n",
        "      self.agefactors[self.gr]=factors\n",
        "      #print(\"Age-Age factors:\", self.agefactors[self.gr] )\n",
        "\n",
        "    self.mean_age_factors={}\n",
        "    for gr_code, factors in self.agefactors.items():\n",
        "      mean=[]\n",
        "      sum_=0\n",
        "      num=0\n",
        "      for i in range(9):\n",
        "        for j in range(9):\n",
        "          if not pd.isnull(factors.iloc[j, i]):\n",
        "            sum_+=factors.iloc[j,i]\n",
        "            num+=1\n",
        "        mean.append(round((sum_/num),4))\n",
        "        sum_=num=0\n",
        "      mean.append(1)          #no extrapolation, assuming it is 1\n",
        "      self.mean_age_factors[self.gr]=mean\n",
        "      #print(\"Mean age factors:\", self.mean_age_factors[self.gr] )\n",
        "\n",
        "\n",
        "  def CDF(self):\n",
        "    self.CDF={}\n",
        "    for gr_code, dupl in self.mean_age_factors.items():\n",
        "      mean=dupl.copy()\n",
        "      for i in range(len(mean)):\n",
        "        prod=1\n",
        "        for j in range(i, len(mean)):\n",
        "          prod*= mean[j]\n",
        "        mean[i]=round(prod,4)\n",
        "      self.CDF[self.gr]=mean\n",
        "    #print(\"CDF:\", self.CDF[self.gr] )\n",
        "    return self.CDF\n",
        "  def develop_triangle(self):\n",
        "    for gr_code, pivot_table in self.pivottables.items() :\n",
        "      #each pivot_table is a triangle, you have to fill the lower triangular values now\n",
        "      #if devolopment lag+ AY >1998, then df[i,j]= df[i,j-1]*cdf[j]\n",
        "      for i in range(pivot_table.shape[0]):\n",
        "          for j in range(pivot_table.shape[1]):\n",
        "            if i+j>9:\n",
        "              pivot_table.iloc[i,j]=pivot_table.iloc[i,j-1]*self.mean_age_factors[self.gr][j-1]\n",
        "    #print(\"Full Triangle:\", self.pivottables[self.gr] )\n",
        "    return self.pivottables\n",
        "\n",
        "#self,df,gr,paid=0,reported=0\n",
        "\n",
        "class method_triangle():\n",
        "  def init(self,tri_paid):\n",
        "    self.tri_paid=tri_paid\n",
        "    self.gr=1\n",
        "\n",
        "  def methods(self):\n",
        "    Actuary_paid=triangle_tri()\n",
        "    self.pivottables_paid=Actuary_paid.get_triangle(self.tri_paid,self.gr,paid=1)\n",
        "    #undeveloped= copy.deepcopy(self.pivottables)\n",
        "    Actuary_paid.init()    ##send gr\n",
        "    self.pivottables_paid_devoloped= Actuary_paid.develop_triangle()\n",
        "    self.CDF_paid=Actuary_paid.CDF()\n",
        "    self.gr=1\n",
        "    self.method={}\n",
        "    self.UC={}\n",
        "\n",
        "    for gr_code, pivot_table in self.pivottables_paid_devoloped.items():\n",
        "      dev_c=[]\n",
        "      dev_f=[]\n",
        "      Age=[]\n",
        "      for i in range(pivot_table.shape[0]):\n",
        "        for j in range(pivot_table.shape[1]):\n",
        "          if i+j==9:\n",
        "            dev_c.append(pivot_table.iloc[i,j])\n",
        "          if j==9:\n",
        "            dev_f.append(pivot_table.iloc[i,j])\n",
        "      for i in range(pivot_table.shape[1],0,-1):\n",
        "        Age.append(12*i)\n",
        "      ibnr=np.array(dev_f) - np.array(dev_c)\n",
        "      dev_c=np.array(dev_c)\n",
        "      dev_f=np.array(dev_f)\n",
        "      cd_factors=np.array(self.CDF_paid[self.gr])\n",
        "      DF = pd.DataFrame()\n",
        "      AY= pivot_table.index.tolist()\n",
        "      DF['AccidentYear']= AY\n",
        "      DF['Age']=Age\n",
        "      DF['Devolopment as of end of {}'.format(AY[0])]=dev_c\n",
        "      DF['Chain Ladder']= dev_f\n",
        "      DF['CDF']=cd_factors\n",
        "\n",
        "      self.UC['Chain Ladder']= DF['Chain Ladder'].sum()\n",
        "\n",
        "      columns=[ 'Chain Ladder']\n",
        "\n",
        "      for i in range(1,len(columns)):\n",
        "        plt.figure(figsize=(5, 3))\n",
        "        plt.plot(DF['AccidentYear'], DF[columns[i]], label=columns[i])\n",
        "        plt.xlabel('Accident Year')\n",
        "        plt.ylabel('Projection')\n",
        "        plt.title('Comparison: {}'.format(columns[i]) )\n",
        "        plt.legend()\n",
        "      self.method[self.gr]=DF\n",
        "    return self.method, self.UC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA8cXSNj3-a_"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgTupUrnoWCp"
      },
      "outputs": [],
      "source": [
        "class triangle() :    #df is the pd dataframe pointing to the input file\n",
        "\n",
        "  def get_triangle(self,df,gr,paid=0,reported=0):\n",
        "    self.df=df\n",
        "    self.pivottables = {}\n",
        "    self.gr=gr\n",
        "    for gr_code, group in df.groupby('GRCODE'):\n",
        "      if gr_code==self.gr:\n",
        "        if paid==1:\n",
        "          pivot_table = group.pivot_table(index='AccidentYear', columns='DevelopmentLag', values='CumPaidLoss')\n",
        "          self.pivottables[self.gr] = pivot_table\n",
        "          self.arima_pivottables = copy.deepcopy(self.pivottables)\n",
        "          self.glm_pivottables= copy.deepcopy(self.pivottables)\n",
        "          #print(\"Upper Triangle:\", self.pivottables[self.gr] )\n",
        "          print(tabulate(self.pivottables[self.gr], showindex=True , headers='keys', tablefmt = 'psql'))\n",
        "          return self.pivottables\n",
        "        if reported==1:\n",
        "          pivot_table = group.pivot_table(index='AccidentYear', columns='DevelopmentLag', values='IncurLoss')\n",
        "          self.pivottables[self.gr] = pivot_table\n",
        "          self.arima_pivottables = copy.deepcopy(self.pivottables)\n",
        "          self.glm_pivottables= copy.deepcopy(self.pivottables)\n",
        "          #print(\"Upper Triangle:\", self.pivottables[self.gr] )\n",
        "\n",
        "          return self.pivottables\n",
        "\n",
        "  def init(self):\n",
        "    for gr_code, pivot_table in self.pivottables.items():\n",
        "      self.agefactors={}\n",
        "      factors=[]\n",
        "      for i in range(9):\n",
        "        P = []\n",
        "        for j in range(9):\n",
        "          if (pivot_table.iloc[i,j] != 0):\n",
        "            f = round(pivot_table.iloc[i,j+1]/pivot_table.iloc[i,j],4)\n",
        "          elif (pivot_table.iloc[i,j] == 0 and pivot_table.iloc[i,j+1] == 0 ):\n",
        "            f = 1\n",
        "          else:\n",
        "            f = None\n",
        "          P.append(f)\n",
        "        factors.append(P)\n",
        "      Accident_Year = [1988+i for i in range(9)]\n",
        "      col = [(12*(i+1),12*(i+2)) for i in range(9)]\n",
        "      DF = pd.DataFrame.from_records(factors,columns = col, index = Accident_Year)\n",
        "      self.agefactors[self.gr]=DF\n",
        "      #print(\"Age-age factors:\", self.agefactors[self.gr] )\n",
        "      print(tabulate(self.agefactors[self.gr], showindex=True , headers='keys', tablefmt = 'psql'))\n",
        "\n",
        "    #def cap_ages(self):\n",
        "    for gr_code, factors in self.agefactors.items():\n",
        "      for i in range(9):\n",
        "        his=[]\n",
        "        for j in range(9):\n",
        "          value=factors.iloc[j,i]\n",
        "          try:\n",
        "              del sum\n",
        "          except :\n",
        "              pass  #somewhere sum is defined as an integer\n",
        "          if his:\n",
        "            count=0\n",
        "            for i in range(len(his)):\n",
        "              count+=his[i]\n",
        "            his_sum = count\n",
        "            mean=his_sum/len(his)\n",
        "            limit=mean+5\n",
        "            if value>limit:\n",
        "              factors.iloc[j,i]=mean\n",
        "          his.append(factors.iloc[j,i])\n",
        "      self.agefactors[self.gr]=factors\n",
        "      #print(\"Age-Age factors:\", self.agefactors[self.gr] )\n",
        "      print(tabulate(self.agefactors[self.gr], showindex=True , headers='keys', tablefmt = 'psql'))\n",
        "\n",
        "    self.arima_agefactors={}\n",
        "    p = 1  # AR order  #needs analysis\n",
        "    d = 1  # Differencing order\n",
        "    q = 1  # MA order\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        for gr_code, factors in self.agefactors.items():\n",
        "          j_list=[]\n",
        "          for i in range(9):\n",
        "            for j in range(9):\n",
        "              if i+j>=9 and j not in j_list:\n",
        "                data=list(factors.iloc[:,j])\n",
        "                series = pd.Series(data)\n",
        "                model = ARIMA(series, order=(p, d, q))\n",
        "                fit_model = model.fit()\n",
        "                predictions= np.array(fit_model.forecast(steps=j))\n",
        "                k=0\n",
        "                for i in range(j):\n",
        "                  factors.iloc[9-j+i,j]= predictions[k]\n",
        "                  k+=1\n",
        "                j_list.append(j)\n",
        "                  #factors.iloc[:,j]=np.array(data)+ np.array(fit_model.forecast(steps=j))\n",
        "                #print(\"full updated data\", np.array(factors.iloc[:,j]))\n",
        "          self.arima_agefactors[self.gr]=factors\n",
        "    #adding the row of 1997\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        for gr_code, factors in self.arima_agefactors.items():\n",
        "          AY= factors.index.tolist()\n",
        "          new_row_data = {column: np.nan for column in self.df.columns}\n",
        "          factors.loc[AY[-1]+1]= new_row_data\n",
        "          for i in range(10):\n",
        "                for j in range(9):\n",
        "                  if i==9:\n",
        "                    data=list(factors.iloc[:,j])\n",
        "                    series = pd.Series(data)\n",
        "                    #print(\"data\", data)\n",
        "                    model = ARIMA(series, order=(p, d, q))\n",
        "                    fit_model = model.fit()\n",
        "                    predictions= np.array(fit_model.forecast(steps=1))\n",
        "                    #print(\"predictions\",predictions)\n",
        "                    factors.iloc[9,j]= predictions[0]\n",
        "          self.arima_agefactors[self.gr]=factors\n",
        "    #adding 120-Ult factor\n",
        "    for gr_code, factors in self.arima_agefactors.items():\n",
        "        factors['(120, Ult)']=1\n",
        "    #print(\"ARIMA factors:\", self.arima_agefactors[self.gr] )\n",
        "    print(tabulate(self.agefactors[self.gr], showindex=True , headers='keys', tablefmt = 'psql'))\n",
        "\n",
        "\n",
        "    self.mean_age_factors={}\n",
        "    for gr_code, factors in self.agefactors.items():\n",
        "      mean=[]\n",
        "      sum_=0\n",
        "      num=0\n",
        "      for i in range(9):\n",
        "        for j in range(9):\n",
        "          if not pd.isnull(factors.iloc[j, i]):\n",
        "            sum_+=factors.iloc[j,i]\n",
        "            num+=1\n",
        "        mean.append(round((sum_/num),4))\n",
        "        sum_=num=0\n",
        "      mean.append(1)          #no extrapolation, assuming it is 1\n",
        "      self.mean_age_factors[self.gr]=mean\n",
        "      print(\"Mean age factors:\", self.mean_age_factors[self.gr] )\n",
        "\n",
        "\n",
        "  def CDF(self):\n",
        "    self.CDF={}\n",
        "    for gr_code, dupl in self.mean_age_factors.items():\n",
        "      mean=dupl.copy()\n",
        "      for i in range(len(mean)):\n",
        "        prod=1\n",
        "        for j in range(i, len(mean)):\n",
        "          prod*= mean[j]\n",
        "        mean[i]=round(prod,4)\n",
        "      self.CDF[self.gr]=mean\n",
        "    print(\"CDF:\", self.CDF[self.gr] )\n",
        "    return self.CDF\n",
        "\n",
        "  def glm_develop_triangle(self):\n",
        "    for gr_code, pivot_table in self.glm_pivottables.items():\n",
        "      for j in range(1,10):\n",
        "        y = np.array(pivot_table.iloc[:10-j,j])\n",
        "        x = np.array(pivot_table.iloc[:10-j, j-1])\n",
        "        #print(\"x\",x)\n",
        "        #print(\"y\",y)\n",
        "        predict_x= np.array(pivot_table.iloc[-j:, j-1])\n",
        "        model = sm.GLM(y, x, family=sm.families.Gaussian())\n",
        "        result = model.fit(method = 'bfgs')      #method = 'bfgs' handles single values\n",
        "        y_predict= np.array(result.predict(predict_x))\n",
        "        #print(\"x_predict\",predict_x)\n",
        "        #print(\"y_predict\",y_predict)\n",
        "        index=-1\n",
        "        for k in range(-1,-j-1,-1):\n",
        "          pivot_table.iloc[k,j]=y_predict[index]\n",
        "          index-=1\n",
        "    return self.glm_pivottables\n",
        "\n",
        "  def develop_triangle(self):\n",
        "    for gr_code, pivot_table in self.pivottables.items() :\n",
        "      #each pivot_table is a triangle, you have to fill the lower triangular values now\n",
        "      #if devolopment lag+ AY >1998, then df[i,j]= df[i,j-1]*cdf[j]\n",
        "      for i in range(pivot_table.shape[0]):\n",
        "          for j in range(pivot_table.shape[1]):\n",
        "            if i+j>9:\n",
        "              pivot_table.iloc[i,j]=pivot_table.iloc[i,j-1]*self.mean_age_factors[self.gr][j-1]\n",
        "    #print(\"Full Triangle:\", self.pivottables[self.gr] )\n",
        "    print(tabulate(self.pivottables[self.gr], showindex=True , headers='keys', tablefmt = 'psql'))\n",
        "\n",
        "    return self.pivottables\n",
        "  def arima_develop_triangle(self):\n",
        "    for gr_code, pivot_table in self.arima_pivottables.items() :\n",
        "        #each pivot_table is a triangle, you have to fill the lower triangular values now\n",
        "        #if devolopment lag+ AY >1998, then df[i,j]= df[i,j-1]*cdf[j]\n",
        "        for i in range(pivot_table.shape[0]):\n",
        "          for j in range(pivot_table.shape[1]):\n",
        "            if i+j>9:\n",
        "              pivot_table.iloc[i,j]=pivot_table.iloc[i,j-1]*self.arima_agefactors[gr_code].iloc[i,j-1]\n",
        "        self.arima_pivottables[self.gr]=pivot_table\n",
        "    return self.arima_pivottables\n",
        "\n",
        "  def premium(self):\n",
        "    self.premium = {}\n",
        "    grouped = self.df.groupby('GRCODE')\n",
        "    for gr_code, group_df in grouped:\n",
        "        table = group_df.groupby('AccidentYear')['EarnedPremNet'].mean().reset_index()\n",
        "        #print(table)\n",
        "        self.premium[self.gr] = table\n",
        "        break\n",
        "    #[1.338589096, 1.279143524, 1.20553075, 1.169688156, 1.136716145, 1.106310002, 1.077488464, 1.050814335, 1.017024053 ] got from https://www.bls.gov/data/inflation_calculator.htm\n",
        "    for gr_code, table in self.premium.items():\n",
        "      table['Onlevel factors']=np.array([1.338589096, 1.279143524, 1.20553075, 1.169688156, 1.136716145, 1.106310002, 1.077488464, 1.050814335, 1.017024053, 1 ])\n",
        "      table['On level Premium']=table['EarnedPremNet']*table['Onlevel factors']\n",
        "      self.premium[self.gr]=table\n",
        "    #print(\"Premium:\",self.premium[self.gr])\n",
        "\n",
        "    return self.premium\n",
        "\n",
        "\n",
        "class report():\n",
        "  def reported(self,pivottables,gr,premium):  #needs reported triangle\n",
        "    #need some information of CumRep\n",
        "    self.premium=premium\n",
        "    self.gr=gr\n",
        "    self.reported={}\n",
        "    self.capecod_ECR={}\n",
        "    #print(pivottables[self.gr])\n",
        "    for gr_code, pivot_table in pivottables.items():\n",
        "      dev_c=[]\n",
        "      dev_f=[]\n",
        "      for i in range(pivot_table.shape[0]):\n",
        "        for j in range(pivot_table.shape[1]):\n",
        "          if i+j==9:\n",
        "            dev_c.append(pivot_table.iloc[i,j])\n",
        "          if j==9:\n",
        "            dev_f.append(pivot_table.iloc[i,j])\n",
        "      dev_c=np.array(dev_c)\n",
        "      dev_f=np.array(dev_f)\n",
        "      percentreported= dev_c/dev_f   #correct\n",
        "      DF = pd.DataFrame()\n",
        "      AY= pivot_table.index.tolist()\n",
        "      DF['AccidentYear']= AY\n",
        "      DF['On level premium']= self.premium[self.gr]['On level Premium']\n",
        "      DF['cumrep']=dev_c     #cum reported as of current(1997/12/31)\n",
        "      DF['pctrep'] =percentreported  #cum reported as of current(1997/12/31) using the devoloped triangle\n",
        "      DF['Used-up Premium'] = self.premium[self.gr]['On level Premium'] *  DF['pctrep']\n",
        "      self.reported[self.gr]=DF\n",
        "      capecod_ecr= DF['cumrep'].sum() / DF['Used-up Premium'].sum()\n",
        "      self.capecod_ECR[self.gr]=capecod_ecr\n",
        "      #print(capecod_ecr)\n",
        "      print(tabulate(self.reported[self.gr], showindex=True , headers='keys', tablefmt = 'psql'))\n",
        "      return self.reported, self.capecod_ECR\n",
        "\n",
        "\n",
        "#self,df,gr,paid=0,reported=0\n",
        "\n",
        "class GLM():\n",
        "  def create(self,df,gr): #df_filtered\n",
        "    self.gr=gr\n",
        "    self.pivottables_inc = {}\n",
        "    for gr_code, group in df.groupby('GRCODE'):\n",
        "      if gr_code==self.gr:\n",
        "        pivot_table = group.pivot_table(index='AccidentYear', columns='DevelopmentLag', values='IncPaid')\n",
        "        self.pivottables_inc[gr_code] = pivot_table\n",
        "    for gr_code, pivot_table in self.pivottables_inc.items():\n",
        "      if gr_code==self.gr:\n",
        "        pivot_table.reset_index(drop=True, inplace=True)\n",
        "        pivot_table.index += 1  # Adjust the index to start from 1\n",
        "        pivot_table.reset_index(inplace=True)\n",
        "        glm_df=pd.melt(pivot_table, id_vars='index', value_vars=None, var_name=None, value_name='value', col_level=None)\n",
        "    glm_df.dropna(inplace=True)\n",
        "    self.glm_df=glm_df\n",
        "    self.glm_df2=copy.deepcopy(self.glm_df)\n",
        "\n",
        "  def fit2(self):\n",
        "    self.glm_df2['DevelopmentLag'] = self.glm_df2['DevelopmentLag'].astype(int)      ###################3\n",
        "    self.glm_df2['index'] = self.glm_df2['index'].astype(int)\n",
        "    self.glm_df2['value'] = self.glm_df2['value'].astype(int)\n",
        "    glmdup_df = self.glm_df2[self.glm_df2['index'] != 1]\n",
        "    x1= np.array(glmdup_df['DevelopmentLag'])\n",
        "    x2= np.array(glmdup_df['index'])\n",
        "    y = np.array(glmdup_df['value'])\n",
        "    x1_2d = x1.reshape(-1, 1)\n",
        "    x2_2d = x2.reshape(-1, 1)\n",
        "    x3=[]\n",
        "    x = np.concatenate((x1_2d, x2_2d), axis=1)\n",
        "    for i in range(len(x)):\n",
        "      specific_values=x[i]\n",
        "      #print(specific_values)\n",
        "      mat = self.glm_df2[(self.glm_df2['DevelopmentLag'] == specific_values[0]) &\n",
        "                (self.glm_df2['index'] == specific_values[1]-1)]['value']\n",
        "      x3.append(mat.values[0])\n",
        "    x3=np.array(x3)\n",
        "    x3_2d = x3.reshape(-1, 1)\n",
        "    x = np.concatenate((x1_2d, x2_2d,x3_2d), axis=1)\n",
        "    model = sm.GLM(y, x, family=sm.families.Gaussian())\n",
        "    z=0 #for Gamma\n",
        "    result = model.fit(method = 'bfgs')      #method = 'bfgs' handles single values\n",
        "    self.result2=result\n",
        "    print(result.summary())\n",
        "  def finish2(self):\n",
        "      predic_x=[]                           #############################\n",
        "      predic_x_1=[]\n",
        "      predic_x_0=[]\n",
        "      start=10\n",
        "      for k in range(2,11):\n",
        "          temp=start\n",
        "          for j in range(k-1):\n",
        "            predic_y=[]\n",
        "            predic_x=[]\n",
        "            #predic_x_0.append(temp) #lag\n",
        "            #predic_x_1.append(k)  #index\n",
        "            mat = self.glm_df2[(self.glm_df2['DevelopmentLag'] == temp-1) &\n",
        "                  (self.glm_df2['index'] ==k)]['value']\n",
        "            predic_x= ([k,temp,mat.values[0]])\n",
        "            #print(predic_x)\n",
        "            predic_y =self.result2.predict(predic_x)\n",
        "            #print(predic_y[0])\n",
        "            #append k,temp,predic_y[0]\n",
        "            #glm_df.loc[len(glm_df)]=np.array([k, temp,predic_y[0]])\n",
        "            new_row={'index':k,'DevelopmentLag':temp, 'value':predic_y[0]}\n",
        "            new_df = pd.DataFrame([new_row])\n",
        "            self.glm_df2 = pd.concat([self.glm_df2, new_df], ignore_index=True)\n",
        "            temp+=1\n",
        "          print()\n",
        "          start-=1\n",
        "      self.glm_df2 = self.glm_df2.sort_values(by=['index','DevelopmentLag'])\n",
        "  def predict2(self):\n",
        "      num_rows, num_columns = self.glm_df2.shape     #################################\n",
        "      self.glm_df2['CumPaid']=0\n",
        "      j = 2  # column index of incremental loss\n",
        "      for i in range(0, num_rows - 10+2, 10):\n",
        "          self.glm_df2.iloc[i,3]=self.glm_df2.iloc[i,j]\n",
        "          i+=1\n",
        "          for k in range(9):\n",
        "              self.glm_df2.iloc[i , 3] = self.glm_df2.iloc[i , j] + self.glm_df2.iloc[i -1, 3]\n",
        "              #print(\"current\",glm_df.iloc[i , j],\"previous\", glm_df.iloc[i -1, 3],\" i:\",i,\" j:\",j , \"curdata: \", glm_df.iloc[i , j],\"Updata:\",glm_df.iloc[i , j] + glm_df.iloc[i -1, 3])\n",
        "              i=i+1\n",
        "      self.glm_df2.head(40)\n",
        "      #print(self.glm_df2)\n",
        "\n",
        "      UC_values=[]\n",
        "      for lag, cp in zip(self.glm_df2['DevelopmentLag'], self.glm_df2['CumPaid']):\n",
        "        if lag==10:\n",
        "          UC_values.append(cp)\n",
        "      print(UC_values)\n",
        "\n",
        "      UC=sum(UC_values)\n",
        "      print(\"Ultimate cost using GLM22\",UC)\n",
        "      return UC_values\n",
        "\n",
        "  def fit(self):\n",
        "     y = np.array(self.glm_df['value'])\n",
        "     self.glm_df['DevelopmentLag'] = self.glm_df['DevelopmentLag'].astype(int)\n",
        "     x1= np.array(self.glm_df['DevelopmentLag'])\n",
        "     x2= np.array(self.glm_df['index'])\n",
        "     x1_2d = x1.reshape(-1, 1)\n",
        "     x2_2d = x2.reshape(-1, 1)\n",
        "     # Stack the predictor matrices horizontally\n",
        "     x = np.concatenate((x1_2d, x2_2d), axis=1)\n",
        "     model = sm.GLM(y, x, family=sm.families.Gaussian())\n",
        "     self.z=0    #2 for Gamma  0 for Gaussian\n",
        "     result = model.fit(method = 'bfgs')      #method = 'bfgs' handles single values\n",
        "     print(result.summary())\n",
        "     self.result=result\n",
        "     self.glm_predict=copy.deepcopy(self.glm_df)\n",
        "     self.glm_df['predicted']=result.predict(x)\n",
        "     y_cap = np.array(self.glm_df['predicted'])\n",
        "     self.residuals_pearson = (y-y_cap)/np.sqrt(np.power(y_cap, self.z))\n",
        "  def finish(self):\n",
        "     #finsih the rectangle\n",
        "     predic_x=[]\n",
        "     predic_x_1=[]\n",
        "     predic_x_0=[]\n",
        "     for i in range(2,11):\n",
        "       temp=10\n",
        "       for j in range(i-1):\n",
        "         #print(i,temp)\n",
        "         predic_x.append([i,temp])\n",
        "         predic_x_0.append(temp) #lag\n",
        "         predic_x_1.append(i)  #index\n",
        "         temp-=1\n",
        "     predic_x=np.array(predic_x)\n",
        "     predic_y=self.result.predict(predic_x)\n",
        "     predic_glm = pd.DataFrame()\n",
        "     predic_glm['index']= np.array(predic_x_1)\n",
        "     predic_glm['DevelopmentLag']= np.array(predic_x_0)\n",
        "     predic_glm['predicted']= np.array(predic_y)\n",
        "     #predic_glm.head(55)\n",
        "     self.glm= pd.concat([self.glm_df, predic_glm], axis=0)\n",
        "\n",
        "  def predict(self):\n",
        "    predic_x=[]\n",
        "    predic_x_1=[]\n",
        "    predic_x_0=[]\n",
        "    predic_y=[]\n",
        "    for k in range(2,11):\n",
        "        temp=10\n",
        "        for j in range(k-1):\n",
        "          #print(i,temp)\n",
        "          predic_x.append([k,temp])\n",
        "          predic_x_0.append(temp) #lag\n",
        "          predic_x_1.append(k)  #index\n",
        "          temp-=1\n",
        "    predic_y =self.result.predict(predic_x)\n",
        "    predic_glm = pd.DataFrame()\n",
        "    predic_glm['index']= np.array(predic_x_1)\n",
        "    predic_glm['DevelopmentLag']= np.array(predic_x_0)\n",
        "    predic_glm['value']=np.array(predic_y)\n",
        "    glm_rect= pd.concat([self.glm_predict, predic_glm], axis=0)\n",
        "    glm_rect = glm_rect.sort_values(by=['index','DevelopmentLag'])\n",
        "    #convert into cumm values\n",
        "    num_rows, num_columns = glm_rect.shape\n",
        "    glm_rect['CumPaid']=0\n",
        "    j = 2  # column index of incurloss\n",
        "    for i in range(0, num_rows - 10+2, 10):\n",
        "        glm_rect.iloc[i,3]=glm_rect.iloc[i,j]\n",
        "        i+=1\n",
        "        for k in range(9):\n",
        "            glm_rect.iloc[i , 3] = glm_rect.iloc[i , j] + glm_rect.iloc[i -1, 3]\n",
        "            #print(\"current\",glm_rect.iloc[i , j],\"previous\", glm_rect.iloc[i -1, 3],\" i:\",i,\" j:\",j , \"curdata: \", glm_rect.iloc[i , j],\"Updata:\",glm_rect.iloc[i , j] + glm_rect.iloc[i -1, 3])\n",
        "            i=i+1\n",
        "    UC_values=[]\n",
        "    for lag, cp in zip(glm_rect['DevelopmentLag'], glm_rect['CumPaid']):\n",
        "      if lag==10:\n",
        "        UC_values.append(cp)\n",
        "    return UC_values\n",
        "\n",
        "  def bootstrap(self):\n",
        "     num_bootstrap=50\n",
        "     bootstrap_ult_cost=[]\n",
        "     #print(residuals_pearson)\n",
        "     for i in range(num_bootstrap):\n",
        "       bootstrapped_values = np.random.choice(self.residuals_pearson, size=100, replace=True)\n",
        "       #print(bootstrapped_values)\n",
        "       self.glm['adjusted predicted']=self.glm['predicted']+(bootstrapped_values* np.sqrt(np.power(self.glm['predicted'], self.z)))\n",
        "       self.glm = self.glm.sort_values(by=['index','DevelopmentLag'])\n",
        "       #print(glm)\n",
        "       #I want to cummulate these values across each accident year\n",
        "       num_rows, num_columns =self.glm.shape\n",
        "       self.glm['CumPaid']=0  #5th column\n",
        "       j = 4  # column index of adjusted predicted\n",
        "       for i in range(0, num_rows - 10+2, 10):\n",
        "           self.glm.iloc[i,5]=self.glm.iloc[i,j]\n",
        "           i+=1\n",
        "           for k in range(9):\n",
        "              self.glm.iloc[i , 5] = self.glm.iloc[i , j] + self.glm.iloc[i -1, 5]\n",
        "              i=i+1\n",
        "       UC=[]\n",
        "       for index, row in self.glm.iterrows():\n",
        "         if row['DevelopmentLag'] == 10:\n",
        "             UC.append(row['CumPaid'])\n",
        "       UC=np.array(UC)\n",
        "       ult_cost=UC.sum()\n",
        "       bootstrap_ult_cost.append(ult_cost)\n",
        "     # Calculate the mean\n",
        "     bootstrap_ult_cost=np.array(bootstrap_ult_cost)\n",
        "     mean_value = np.mean(bootstrap_ult_cost)\n",
        "     # Calculate the standard deviation\n",
        "     std_deviation = np.std(bootstrap_ult_cost)\n",
        "     # Print or use the mean and standard deviation\n",
        "     print(\"Mean:\", mean_value)\n",
        "     print(\"Standard Deviation:\", std_deviation)\n",
        "     summary = np.percentile(bootstrap_ult_cost, [25, 50, 75,95])\n",
        "     print(\"Summary (25th, 50th, 75th and 95th percentiles):\", summary)\n",
        "     return bootstrap_ult_cost\n",
        "\n",
        "  def bootstrap_cl(self):\n",
        "    num_bootstrap=50\n",
        "    bootstrap_results=[]\n",
        "    predic_x=[]\n",
        "    predic_x_1=[]\n",
        "    predic_x_0=[]\n",
        "    #print(residuals_pearson)\n",
        "    for i in range(num_bootstrap):\n",
        "      bootstrapped_values = np.random.choice(self.residuals_pearson, size=55, replace=True)\n",
        "      bootstrap_df=pd.DataFrame()\n",
        "      bootstrap_df['index']= self.glm_df['index']\n",
        "      bootstrap_df['DevelopmentLag']= self.glm_df['DevelopmentLag']\n",
        "      bootstrap_df['value']=self.glm_df['predicted']+(bootstrapped_values* np.sqrt(np.power(self.glm_df['predicted'], self.z)))\n",
        "      #got the triangle\n",
        "      for k in range(2,11):\n",
        "        temp=10\n",
        "        for j in range(k-1):\n",
        "          #print(i,temp)\n",
        "          predic_x.append([k,temp])\n",
        "          predic_x_0.append(temp) #lag\n",
        "          predic_x_1.append(k)  #index\n",
        "          temp-=1\n",
        "      predic_glm = pd.DataFrame()\n",
        "      predic_glm['index']= np.array(predic_x_1)\n",
        "      predic_glm['DevelopmentLag']= np.array(predic_x_0)\n",
        "      #predic_glm.head(55)\n",
        "      bootstrap_df= pd.concat([bootstrap_df, predic_glm], axis=0)\n",
        "      bootstrap_df= bootstrap_df.sort_values(by=['index','DevelopmentLag'])\n",
        "      num_rows, num_columns = bootstrap_df.shape\n",
        "      bootstrap_df['Cum']=0\n",
        "      j = 2  # column index of inc loss\n",
        "      for i in range(0, num_rows - 10+2, 10):\n",
        "          bootstrap_df.iloc[i,3]=bootstrap_df.iloc[i,j]\n",
        "          i+=1\n",
        "          for k in range(9):\n",
        "              bootstrap_df.iloc[i , 3] = bootstrap_df.iloc[i , j] + bootstrap_df.iloc[i -1, 3]\n",
        "              #print(\"current\",bootstrap_df.iloc[i , j],\"previous\", bootstrap_df.iloc[i -1, 3],\" i:\",i,\" j:\",j , \"curdata: \", bootstrap_df.iloc[i , j],\"Updata:\",bootstrap_df.iloc[i , j] - bootstrap_df.iloc[i -1, 3])\n",
        "              i=i+1\n",
        "      predic_x=[]\n",
        "      predic_x_1=[]\n",
        "      predic_x_0=[]\n",
        "      pivot_table = pd.pivot_table(bootstrap_df, index='index', columns='DevelopmentLag', values='Cum')\n",
        "      Actuary=method_triangle()\n",
        "      triangle_array = pivot_table.values.copy()\n",
        "      Actuary.init(pivot_table)\n",
        "      results=[Actuary.methods()]\n",
        "      bootstrap_results.append(results[0][1]['Chain Ladder'])\n",
        "      print(bootstrap_results)            ###############check once\n",
        "    summary = np.percentile(bootstrap_results, [25, 50, 75,95])\n",
        "    print(\"Summary (25th, 50th, 75th and 95th percentiles):\", summary)\n",
        "    return bootstrap_results\n",
        "\n",
        "\n",
        "\n",
        "class method():\n",
        "  def methods(self,df,gr,flag=0):\n",
        "\n",
        "    Actuary_validate=triangle()\n",
        "    self.pivottables_verify=Actuary_validate.get_triangle(df,gr,paid=1) #for verification\n",
        "\n",
        "    df = df[(df['AccidentYear'] + df['DevelopmentLag']) <= 1998]  #upper triangle\n",
        "    #df.info()\n",
        "    Actuary_paid=triangle()\n",
        "    self.pivottables_paid=Actuary_paid.get_triangle(df,gr,paid=1)\n",
        "    #bootstrapping here?\n",
        "\n",
        "    Actuary_paid.init()\n",
        "    self.pivottables_paid_devoloped= Actuary_paid.develop_triangle()\n",
        "    self.pivottables_paid_devoloped_arima= Actuary_paid.arima_develop_triangle()\n",
        "    self.premium=Actuary_paid.premium()\n",
        "    self.CDF_paid=Actuary_paid.CDF()\n",
        "    self.arima_pivottables_paid= Actuary_paid.arima_develop_triangle()\n",
        "    self.glm_pivottables_paid= Actuary_paid.glm_develop_triangle()\n",
        "\n",
        "    Actuary_reported=triangle()\n",
        "    self.pivottables_reported=Actuary_reported.get_triangle(df,gr,reported=1)\n",
        "    Actuary_reported.init()\n",
        "    self.pivottables_reported_devoloped= Actuary_reported.develop_triangle()\n",
        "    self.pivottables_reported_devoloped_arima= Actuary_reported.arima_develop_triangle()\n",
        "    self.CDF_reported=Actuary_reported.CDF()\n",
        "    self.arima_pivottables_reported= Actuary_reported.arima_develop_triangle()\n",
        "\n",
        "    Actuary_report=report()\n",
        "    self.reported, self.capecod_ECR =Actuary_report.reported(self.pivottables_reported,gr,self.premium)\n",
        "\n",
        "    self.gr=gr\n",
        "    self.method={}\n",
        "    self.accuracy={}\n",
        "    self.UC={}\n",
        "    Actuary_glm=GLM()\n",
        "    Actuary_glm.create(df,gr)\n",
        "    Actuary_glm.fit()\n",
        "    Actuary_glm.fit2()\n",
        "    Actuary_glm.finish()\n",
        "    Actuary_glm.finish2()\n",
        "    self.GLM_UC=Actuary_glm.predict()\n",
        "    self.GLM2_UC=Actuary_glm.predict2()\n",
        "    self.bootstrap_ult_cost=Actuary_glm.bootstrap()  #use this for graphs\n",
        "    self.bootstrap_ult_cost_cl=Actuary_glm.bootstrap_cl()\n",
        "\n",
        "\n",
        "    for gr_code, pivot_table in self.pivottables_paid_devoloped.items():\n",
        "      actual_reported_claims=[]\n",
        "      dev_f_arima=[]\n",
        "      dev_f_glm=[]\n",
        "      dev_c=[]\n",
        "      dev_f=[]\n",
        "      Age=[]\n",
        "      Premium=self.premium[self.gr]['EarnedPremNet']\n",
        "      Premium=np.array(Premium)\n",
        "      onlevelPremium=self.premium[self.gr]['On level Premium']\n",
        "      onlevelPremium=np.array(onlevelPremium)\n",
        "      for i in range(pivot_table.shape[0]):\n",
        "        for j in range(pivot_table.shape[1]):\n",
        "          if i+j==9:\n",
        "            dev_c.append(pivot_table.iloc[i,j])\n",
        "            actual_reported_claims.append(self.pivottables_reported[self.gr].iloc[i,j])\n",
        "          if j==9:\n",
        "            dev_f.append(pivot_table.iloc[i,j])\n",
        "            dev_f_arima.append(self.arima_pivottables_paid[gr_code].iloc[i,j])\n",
        "            dev_f_glm.append(self.glm_pivottables_paid[gr_code].iloc[i,j])\n",
        "      for i in range(pivot_table.shape[1],0,-1):\n",
        "        Age.append(12*i)\n",
        "      ibnr=np.array(dev_f) - np.array(dev_c)\n",
        "      actual_reported_claims=np.array(actual_reported_claims)\n",
        "      dev_c=np.array(dev_c)\n",
        "      dev_f=np.array(dev_f)\n",
        "      with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
        "        ecratio = np.array(dev_f) / Premium\n",
        "      ecr_1=[]\n",
        "      ecr_2=[]\n",
        "      for i in range(pivot_table.shape[0]//2):\n",
        "        ecr_1.append(ecratio[i])\n",
        "      ecr_1mean=sum(ecr_1)/len(ecr_1)\n",
        "      for i in range(pivot_table.shape[0]//2,pivot_table.shape[0]):\n",
        "        ecr_2.append(ecratio[i])\n",
        "      ecr_2mean=sum(ecr_2)/len(ecr_2)\n",
        "      selected_ecr1 = [ecr_1mean] *(pivot_table.shape[0]//2)\n",
        "      selected_ecr2 = [ecr_2mean] *(pivot_table.shape[0]//2)\n",
        "      selected_ecr= selected_ecr1+ selected_ecr2\n",
        "      selected_ecr=np.array(selected_ecr)\n",
        "      Exp_Ult= Premium * selected_ecr\n",
        "      cd_factors=np.array(self.CDF_paid[self.gr])\n",
        "      reported_pct=dev_c/dev_f           ###done\n",
        "      #print(\"Reported %\",reported_pct)\n",
        "      #print(Exp_Ult)\n",
        "      DF = pd.DataFrame()\n",
        "      AY= pivot_table.index.tolist()\n",
        "      DF['AccidentYear']= AY\n",
        "      DF['Age']=Age\n",
        "      DF['Devolopment as of end of {}'.format(AY[0])]=dev_c\n",
        "      DF['Chain Ladder']= dev_f\n",
        "      DF['ARIMA Chain Ladder']= dev_f_arima\n",
        "      #DF['IBNR paid chainladder']=ibnr\n",
        "      DF['Premium']=Premium\n",
        "      DF['EC ratio']= ecratio\n",
        "      DF['Selected EC ratio'] =selected_ecr\n",
        "      DF['Expected Ult Loss']= Exp_Ult\n",
        "      DF['CDF']=cd_factors\n",
        "      DF['BF']= (dev_c) + ((1-reported_pct)* Exp_Ult)\n",
        "      #print(capecod_ECR[gr_code])\n",
        "      DF['On level premium']= onlevelPremium\n",
        "      DF['capecodECR']=self.capecod_ECR[self.gr]\n",
        "      #DF['ECR expected paid claims']= ((1-reported_pct)* Exp_Ult)\n",
        "      expected_unreported_claims= np.array((onlevelPremium* self.capecod_ECR[self.gr])*(1-self.reported[self.gr]['pctrep']))\n",
        "      DF['Cape-cod Ult paid claims']=   actual_reported_claims+  expected_unreported_claims\n",
        "      DF['GLM']= dev_f_glm\n",
        "      DF['GLM2']=np.array(self.GLM_UC)\n",
        "      DF['GLM2(2)']=np.array(self.GLM2_UC)\n",
        "      DF['Original UC']= np.array(self.pivottables_verify[self.gr].iloc[:,-1])\n",
        "      #DF['Cape-cod Ult paid check']=   (dev_c) + ((capecod_ECR[gr_code])* Exp_Ult)\n",
        "      #DF['IBNR capecod']= DF['UC capecod']*(1-reported[gr_code]['pctrep'])\n",
        "      statements=[\n",
        "       \"r2_1 = r2_score( np.array(DF['Original UC']), np.array(DF['Chain Ladder']))\",\n",
        "       \"r2_2 = r2_score( np.array(DF['Original UC']), np.array(DF['ARIMA Chain Ladder']))\",\n",
        "       \"r2_3 = r2_score( np.array(DF['Original UC']), np.array(DF['Expected Ult Loss']))\",\n",
        "       \"r2_4 = r2_score( np.array(DF['Original UC']), np.array(DF['BF']))\",\n",
        "       \"r2_5= r2_score( np.array(DF['Original UC']), np.array(DF['Cape-cod Ult paid claims']))\",\n",
        "       \"r2_6= r2_score( np.array(DF['Original UC']), np.array(DF['GLM']))\",\n",
        "       \"r2_7= r2_score( np.array(DF['Original UC']), np.array(DF['GLM2']))\",\n",
        "       \"r2_8= r2_score( np.array(DF['Original UC']), np.array(DF['GLM2(2)']))\",\n",
        "       \"self.accuracy['Chain Ladder']=r2_1\",\n",
        "       \"self.accuracy['ARIMA Chain Ladder']=r2_2\",\n",
        "       \"self.accuracy['Expected Ult Loss']=r2_3\",\n",
        "       \"self.accuracy['BF']=r2_4\",\n",
        "       \"self.accuracy['Cape-cod Ult paid claims']=r2_5\",\n",
        "       \"self.accuracy['GLM']=r2_6\",\n",
        "       \"self.accuracy['GLM2']=r2_7\",\n",
        "       \"self.accuracy['GLM2(2)']=r2_8\",\n",
        "       \"print(self.accuracy)\",\n",
        "\n",
        "       \"self.UC['Chain Ladder']= DF['Chain Ladder'].sum()\",\n",
        "       \"self.UC['ARIMA Chain Ladder']=DF['ARIMA Chain Ladder'].sum()\",\n",
        "       \"self.UC['Expected Ult Loss']=DF['Expected Ult Loss'].sum()\",\n",
        "       \"self.UC['BF']=DF['BF'].sum()\",\n",
        "       \"self.UC['Cape-cod Ult paid claims']=DF['Cape-cod Ult paid claims'].sum()\",\n",
        "       \"self.UC['GLM']=DF['GLM'].sum()\",\n",
        "       \"self.UC['GLM2']=DF['GLM2'].sum()\",\n",
        "       \"self.UC['Original UC']=DF['Original UC'].sum()\",\n",
        "       \"self.UC['GLM Bootstrap']=np.mean(self.bootstrap_ult_cost)\",\n",
        "       \"self.UC['GLM Bootstrap CL']=np.mean(self.bootstrap_ult_cost_cl)\",\n",
        "       \"self.UC['GLM2(2)']=DF['GLM2(2)'].sum()\",\n",
        "\n",
        "       \"original_uc_value = self.UC['Original UC']\",\n",
        "       \"differences = {key: value- original_uc_value  for key, value in self.UC.items() if key != 'Original UC'}\",\n",
        "       \"plt.figure(figsize=(10, 6))\",\n",
        "       \"print('Differences:   ',differences)\",\n",
        "       \"plt.bar(differences.keys(), differences.values(), color='red')\",\n",
        "       \"plt.axhline(0, color='gray', linewidth=0.5)\",\n",
        "       \"plt.xlabel('Models')\",\n",
        "       \"plt.ylabel('Difference from Original UC')\",\n",
        "       \"plt.title('Comparison with Original UC')\",\n",
        "       \"plt.xticks(rotation=45, ha='right')\" ,\n",
        "       \"plt.tight_layout()\",\n",
        "       \"plt.show()\"  ]\n",
        "\n",
        "      for statement in statements:\n",
        "       try:\n",
        "         exec(statement)\n",
        "       except :\n",
        "         pass\n",
        "\n",
        "      columns=['Original UC', 'GLM', 'GLM2','GLM2(2)', 'Cape-cod Ult paid claims', 'BF', 'Expected Ult Loss', 'ARIMA Chain Ladder', 'Chain Ladder']\n",
        "      for i in range(1,len(columns)):\n",
        "        plt.figure(figsize=(5, 3))\n",
        "        try:\n",
        "         plt.plot(DF['AccidentYear'], DF[columns[i]], label=columns[i])\n",
        "        except:\n",
        "         pass\n",
        "        plt.plot(DF['AccidentYear'], DF[columns[0]], label=columns[0])\n",
        "        plt.xlabel('Accident Year')\n",
        "        plt.ylabel('Projection')\n",
        "        try:\n",
        "           plt.title('Comparison: {}. R2={}'.format(columns[i],self.accuracy[columns[i]]))\n",
        "        except :\n",
        "         pass\n",
        "        plt.legend()\n",
        "        #print(DF['Cape-cod Ult paid claims'].sum())\n",
        "        #print(DF['Original UC'].sum())\n",
        "      self.method[self.gr]=DF\n",
        "\n",
        "\n",
        "      plt.figure(figsize=(5, 3))\n",
        "      for i in range(1,len(columns)):\n",
        "        try:\n",
        "         if columns[i] in ['Original UC', 'ARIMA Chain Ladder']:  # Highlight specific columns\n",
        "            plt.plot(DF['AccidentYear'], DF[columns[i]], label=columns[i], linewidth=4)\n",
        "         else:\n",
        "            plt.plot(DF['AccidentYear'], DF[columns[i]], label=columns[i], alpha=0.2)\n",
        "        except:\n",
        "         pass\n",
        "      plt.plot(DF['AccidentYear'], DF[columns[0]], label=columns[0])\n",
        "      plt.xlabel('Accident Year')\n",
        "      plt.ylabel('Projection')\n",
        "      plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "\n",
        "    return self.method, self.accuracy, self.UC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUUSstgiOLBp"
      },
      "source": [
        "For a single company"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efBYUTn4CFv7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Actuary/Project- Reserving/merged_data.csv')\n",
        "df = df[df['Line_of_Business_LOB2'] == 1]\n",
        "df_filtered= df[(df['AccidentYear'] + df['DevelopmentLag']) <= 1998] #upper trianlge\n",
        "#take a company code\n",
        "gr= 669 #44504\n",
        "Actuary=method()\n",
        "results=[Actuary.methods(df,gr)]\n",
        "print(results)\n",
        "print(tabulate(results[0][0][gr], showindex=True , headers='keys', tablefmt = 'psql'))\n",
        "#results[0][2]['Chain Ladder'] is our chianladder UC reserve estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSHOV4PnOO3r"
      },
      "source": [
        "Analysis of multiple companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHbq--25rsCt",
        "outputId": "892fc630-1e11-40ed-e328-f1b7135636f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaWMHriM8cyE"
      },
      "outputs": [],
      "source": [
        "#LOB1->commercial auto\n",
        "#LOB2->medical malpractices\n",
        "#LOB3->other liabilities\n",
        "#LOB4->private passengers\n",
        "#LOB5->product liabilities\n",
        "#LOB6->worker's compensation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ0sdh33mvzg"
      },
      "outputs": [],
      "source": [
        "random_elements=[\n",
        "    [337,353,388,620, 715],\n",
        "    [669,7854,32514,33049,33111],\n",
        "    [460,620,671,683,715],\n",
        "    [43,266,353,388,460],\n",
        "    [78,86,353,388,620],\n",
        "    [86,337,353,388,671]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqw6LHrfWb4y"
      },
      "outputs": [],
      "source": [
        "column_names = ['LOB','gr', 'Chain Ladder', 'ARIMA Chain Ladder', 'Expected Ult Loss', 'BF','Cape-cod Ult paid claims', 'GLM','GLM2','GLM2(2)', 'Original UC', 'GLM Bootstrap', 'GLM Bootstrap CL',\n",
        "                  'Error in Chian Ladder', 'Error in ARIMA Chain Ladder', 'Error in Expected Ult Loss','Error in BF', 'Error in Cape-cod Ult paid claims', 'Error in GLM','Error in GLM2','Error in GLM2(2)','Error in GLM Bootstrap','Error in GLM Bootstrap CL','Best R2', 'Best in terms of error in UC']\n",
        "print(len(column_names))\n",
        "info = pd.DataFrame(columns=column_names)\n",
        "for i in range(1,7):\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Shashi/merged_data.csv')\n",
        "  string='Line_of_Business_LOB{}'.format(i)\n",
        "  #print(string)\n",
        "  df=df[df[string]==1]\n",
        "  for gr in random_elements[i-1]:\n",
        "    Actuary=method()\n",
        "    results=[Actuary.methods(df,gr)]\n",
        "    #print(results)\n",
        "    #print(results[0][2])\n",
        "    #print(results[0][1])\n",
        "    errors={}\n",
        "    for key, valaue in results[0][2].items():\n",
        "        if key!='Original UC':\n",
        "          errors[key]=results[0][2][key]-results[0][2]['Original UC']\n",
        "\n",
        "\n",
        "    max_key = max(results[0][1], key=results[0][1].get)      #max R2\n",
        "    min_key=min(errors, key=lambda k: abs(errors[k]))        #min UC error\n",
        "    input=[list(results[0][2].values()),list(errors.values()),max_key, min_key]\n",
        "    input_row = [element for sublist in input for element in sublist if type(element) != str]\n",
        "    input_row.append(input[-2])\n",
        "    input_row.append(input[-1])\n",
        "    input_row.insert(0,gr)\n",
        "    input_row.insert(0,i)\n",
        "    print(input_row)\n",
        "    print(len(input_row))\n",
        "    #append input_row to info\n",
        "    info.loc[len(info)]=input_row\n",
        "    #info = info.append(input_row, ignore_index=True)\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUv5NR_HgOaf"
      },
      "outputs": [],
      "source": [
        "dup = copy.deepcopy(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzPkdNRh2S3_"
      },
      "outputs": [],
      "source": [
        "info.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRBkKlfIqgin",
        "outputId": "21089d02-bd72-4e12-8bb4-9703b9bad688"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-70ae07816973>:12: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  writer.save()\n"
          ]
        }
      ],
      "source": [
        "writer= pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
        "info.to_excel(writer, index=False, sheet_name='results', startrow=1)\n",
        "\n",
        "# Access the xlsxwriter workbook and worksheet objects\n",
        "workbook  = writer.book\n",
        "worksheet = writer.sheets['results']\n",
        "\n",
        "# Set the width of all columns to 15\n",
        "for col_num, value in enumerate(info.columns.values):\n",
        "    worksheet.set_column(col_num, col_num, width=28)\n",
        "# Save the Excel file\n",
        "writer.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGaHpRa-OUSc"
      },
      "source": [
        "Download the output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCi51CRIq4OF"
      },
      "outputs": [],
      "source": [
        "#AWESOME- DONE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}